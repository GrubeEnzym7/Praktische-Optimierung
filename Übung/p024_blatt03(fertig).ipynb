{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textbf{Blatt 03 - Praktische Optimierung - Adrian Lentz, Robert}$$\n",
    "\n",
    "Lösungen und Erklärungen für Blatt 03. $$\\newline$$\n",
    "Adrian Lentz - Matrikelnummer: 258882 $$\\newline$$\n",
    "Robert Schönewald - Matrikelnummer: 188252"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textbf{Aufgabe 3.1}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from kompasssuche_test import kompasssuche_test\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.distributions.empirical_distribution as edf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Funktion definieren'\n",
    "\n",
    "def f_a(x):\n",
    "    return x[0]**2 + x[1]**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "stichprobe= random_points = np.random.uniform(-10, 10, (500, 2))   #Punkte generieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Parametereinstellungen'\n",
    "\n",
    "parameter = [\n",
    "    (1.0, 0.5),\n",
    "    (2.0, 0.5),\n",
    "    (1.5, 0.8),\n",
    "    (0.5, 0.2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Zeitmessung - Definition'\n",
    "def zeitmessung(f_a,x0,s0,theta):\n",
    "    zeit= lambda:kompasssuche_test(f_a,x0,s0,theta)   #Lambda Funktion ersparrt definieren von zeit über funktion der Kompassuche\n",
    "    return timeit.timeit(zeit,number=1)                                 #timeit.timeit gibt Messung der Laufzeit wieder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Zeitmessung - Ausführung'\n",
    "zeiten=[]\n",
    "for i, (s0, theta) in enumerate(parameter):     #einmal alle Parameter durchgehen\n",
    "    para_zeiten=[]                              #Zeiten für die jeweiligen Parameter werden hier gespeichert\n",
    "    for x0 in stichprobe:\n",
    "        curr_times=[]                          #Zeiten für die aktuellen zufälligen Startwerte\n",
    "        for j in range(100):                   #Messung 100mal wiederholen\n",
    "            curr_times.append(zeitmessung(f_a, x0, s0, theta))\n",
    "        para_zeiten.append(np.median(curr_times))\n",
    "    zeiten.append(para_zeiten)\n",
    "print(len(zeiten[0]))  #Test der Länge, sollte 500 lang sein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(zeiten)\n",
    "ax.set_xticklabels(['(1, 0.5)','(2, 0.5)','(1.5, 0.8)','(0.5, 0.2)'])\n",
    "ax.set(xlabel='Parameter', ylabel='mediane Zeiten')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die erste Sache die bei Betrachtung der Boxplots auffällt, ist dass die Parameterkombination (1.5, 0.8) deutlich höhere Zeiten erreicht als die \n",
    "anderen Parameter. Die Schrittweite wird hier am langsamsten verrringert, was dazu führt, dass viele unnötige Iterationen durchgeführt werden, da die\n",
    "Schrittweite immer noch zu lang ist. Dazu kommt noch, dass die initiale Schrittweite mit 1.5 relativ hoch ist. \\\n",
    "Die Parameter (0.5, 0.2) erzeugen einen Boxplot mit sehr hoher Varianz, ihre schnellste und langsamste Zeit scheint mit der von allen Parameterpaaren \n",
    "übereinzustimmen. Dies lässt sich durch eine Sehr kleine initiale Schrittweite erklären. Zusätzlich wird diese auch nur sehr langsam verändert. Der\n",
    "Erfolg dieser Parameter hängt stark von der Startposition ab, da bei großer Entfernung zum Optimum ein sehr langer Weg begangen werden muss, bei kleiner\n",
    "Entfernung wird das Optimum bereits schnell genau gefunden.\\\n",
    "Die ersten beiden Paare (1, 0.5) (hier A genannt) und (2, 0.5) (hier B genannt) lassen erkennen, dass B deutlich weniger schwankt. Insgesamt scheint B \n",
    "die bessere Wahl zu sein, da der Median und die beiden Quartile unter denen von A liegen. Jedoch ist das Minimum von beiden in A. Da sich beide Paare \n",
    "nur in der initialen Schrittweite unterscheiden, lässt sich daraus schließen, dass eine größere Schrittweite meistens schneller ist, jedoch ermöglicht\n",
    "eine kürzere Schrittweite das Finden des Optimums in minimaler Zeit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Aufstellen der Hypothesen'\n",
    "\n",
    "print('Hypothese (i):')\n",
    "'H0: Parameterpaar (1,0.5) ist im Mittel langsamer oder gleich schnell als (1.5,0.8)'\n",
    "'H1: Parameterpaar (1,0.5) ist im Mittel schneller als (1.5,0.8)'\n",
    "\n",
    "print('Welch-Test:')\n",
    "tstat1, p1 = scipy.stats.ttest_ind(zeiten[0],zeiten[2],equal_var=False,alternative='less')\n",
    "print(\"t-statistic:\",tstat1)\n",
    "print(\"p-value:\",p1,end=\"\\n\"+\"\\n\")\n",
    "\n",
    "print('Wilcoxon-Test:')\n",
    "tstat1, p1 = scipy.stats.ranksums(zeiten[0],zeiten[2],alternative='less')\n",
    "print(\"t-statistic:\",tstat1)\n",
    "print(\"p-value:\",p1,end=\"\\n\"+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wurde der optionale Parameter alternative der Tests auf less verändert. Damit wird die alternative Hypothese verändert, sodass nun nicht mehr auf Ungleichheit getestet wird, sondern ob Verteilung des ersten Parameters kleiner ist als die des zweiten, so wie in der Aufgabe erwünscht. Dieser Test hat sehr kleine p-Werte, weswegen es sehr wahrscheinlich ist, dass die erste Hypothese zutrifft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hypothese (ii):')\n",
    "'H0: Parameterpaar (1.5,0.8) ist im Mittel langsamer oder gleich schnell als (0.5,0.2)'\n",
    "'H1: Parameterpaar (1.5,0.8) ist im Mittel schneller als (0.5,0.2)'\n",
    "\n",
    "print('Welch-Test:')\n",
    "tstat2, p2 = scipy.stats.ttest_ind(zeiten[2],zeiten[3],equal_var=False,alternative='less')\n",
    "print(\"t-statistic:\",tstat2)\n",
    "print(\"p-value:\",p2,end=\"\\n\"+\"\\n\")\n",
    "\n",
    "print('Wilcoxon-Test:')\n",
    "tstat2, p2 = scipy.stats.ranksums(zeiten[2],zeiten[3],alternative='less')\n",
    "print(\"t-statistic:\",tstat2)\n",
    "print(\"p-value:\",p2,end=\"\\n\"+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Testergebnisse liefern p-Werte von 1, weswegen keine Aussage über die zweite Hypothese gemacht werden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hypothese (iii):')\n",
    "'H0: Parameterpaar (2,0.5) ist im Mittel langsamer oder gleich schnell als (1.5,0.8)'\n",
    "'H1: Parameterpaar (2,0.5) ist im Mittel schneller als (1.5,0.8)'\n",
    "\n",
    "print('Welch-Test:')\n",
    "tstat3, p3 = scipy.stats.ttest_ind(zeiten[1],zeiten[2],equal_var=False,alternative='less')\n",
    "print(\"t-statistic:\",tstat3)\n",
    "print(\"p-value:\",p3,end=\"\\n\"+\"\\n\")\n",
    "\n",
    "print('Wilcoxon-Test:')\n",
    "tstat3, p3 = scipy.stats.ranksums(zeiten[1],zeiten[2],alternative='less')\n",
    "print(\"t-statistic:\",tstat3)\n",
    "print(\"p-value:\",p3,end=\"\\n\"+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ähnlich wie in der ersten Hypothese erhalten wir sehr niedrige p-Werte, die dritte Hypothese wahrscheinlich zutrifft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hypothese (iv):')\n",
    "'H0: Parameterpaar (1,0.5) ist im Mittel langsamer oder gleich schnell als (0.5,0.2)'\n",
    "'H1: Parameterpaar (1,0.5) ist im Mittel schneller als (0.5,0.2)'\n",
    "\n",
    "print('Welch-Test:')\n",
    "tstat4, p4 = scipy.stats.ttest_ind(zeiten[0],zeiten[3],equal_var=False,alternative='less')\n",
    "print(\"t-statistic:\",tstat4)\n",
    "print(\"p-value:\",p4,end=\"\\n\"+\"\\n\")\n",
    "\n",
    "print('Wilcoxon-Test:')\n",
    "tstat4, p4 = scipy.stats.ranksums(zeiten[0],zeiten[3],alternative='less')\n",
    "print(\"t-statistic:\",tstat4)\n",
    "print(\"p-value:\",p4,end=\"\\n\"+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie bereits vorher gesehen, scheint es so als ob wir die vierte Hypothese wahrscheinlich wahr ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die vorher gesehenen Boxplots scheinen mit diesen Ergebnissen übereinzustimmen: \\\n",
    "(i) 1 ist schneller als 3 \\\n",
    "(ii) 3 ist nicht schneller als 4 \\\n",
    "(iii) 2 ist schneller als 3 \\\n",
    "(iv) 1 ist schneller als 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für den Welch-Test nehmen wir an, dass die Verteilungen normalverteilt sind und die Varianzen gleich sind. Letzteres haben wir durch den Parameter equal_var umgangen. Überprüfen wir nun also ob unsere Ergebnisse normalverteilt sind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(np.array(zeiten[0]),line=\"s\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(np.array(zeiten[1]),line=\"s\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(np.array(zeiten[2]),line=\"s\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(np.array(zeiten[3]),line=\"s\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Diagramme lassen darauf schließen, dass die Verteilungen wahrscheinlich normalverteilt sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecdf = edf.ECDF(zeiten[0])\n",
    "\n",
    "x = np.linspace(min(zeiten[0]), max(zeiten[0]))\n",
    "y = ecdf(x)\n",
    "plt.step(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecdf = edf.ECDF(zeiten[1])\n",
    "\n",
    "x = np.linspace(min(zeiten[1]), max(zeiten[1]))\n",
    "y = ecdf(x)\n",
    "plt.step(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecdf = edf.ECDF(zeiten[2])\n",
    "\n",
    "x = np.linspace(min(zeiten[2]), max(zeiten[2]))\n",
    "y = ecdf(x)\n",
    "plt.step(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecdf = edf.ECDF(zeiten[3])\n",
    "\n",
    "x = np.linspace(min(zeiten[0]), max(zeiten[3]))\n",
    "y = ecdf(x)\n",
    "plt.step(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch diese Diagramme lassen darauf schließen, dass die Daten normalverteilt sind. Zusätzlich lässt sich vermuten, dass die Verteilungsfunktion stetig ist, wie im Wilcoxon-Test gefordert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insgesamt lässt sich vermuten, dass die Verteilungen alle normalverteilt (somit identisch verteilt), unabhängig und stetig sind. Somit sind alle Vorraussetzungen für die Welch- und Wilcoxon-Tests erfüllt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textbf{Aufgabe 3.2}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H0: \\Theta \\neq \\Theta_{0}$   $\\textbf{vs.}$ $H1: \\Theta = \\Theta_{0}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Nicht relevant für Aufgabe}$\\\n",
    "$\\textit{Erklärung der Begriffe:}$\\\n",
    "Signifikanzniveau $\\alpha$ gibt Wahrscheinlichkeit an,dass wahre Nullhypothese (H0) fälschlicherweise abgelehnt wird.\\\n",
    "Gütefunktion gibt für alle Parameterwerte die Wahrscheinlichkeit an, die Nullhypothese abzulehnen.\\\n",
    "Für $\\theta$ aus $\\Theta_{0}$: Gütefunktion misst Wahrscheinlichkeit H0 abzulehnen, obwohl richtig --> Deswegen hier möglichst kleinen Wert für einen guten Test .\\\n",
    "Für $\\theta$ aus $\\Theta_{1}$: Gütefunktion misst Wahrscheinlichkeit H0 abzulehnen, wenn falsch ist --> Deswegen hier möglichst großen Wert für guten Test.\\\n",
    "--> Fehler 1.Art : Wahrscheinlichkeit Nullhypothese ablehnen, obwohl sie richig ist. Durch $\\alpha$ angegeben \\\n",
    "--> Fehler 2.Art : Wahrscheinlichkeit Nullhypothese nicht abzulehnen, obwohl falsch ist \\\n",
    "Kritische Bereich festgelegt, sodass  Wahrscheinlichkeit in diesem Bereich gleich dem Signifikanzniveau $\\alpha$ entspricht, wenn Nullhypothese wahr ist.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beispiel für einen zweiseitigen Test mit dem Parameter $\\mu$:\n",
    "\\\n",
    "Hier ist die Nullhypothese wahr für $\\mu = \\mu_{0}$.\\\n",
    "Das heißt eine Ablehnung der wahren Nullhypothese (Fehler 1.Art) führt zu einer Wahrscheinlichkeit P(H1/H0)= $\\alpha$.\\\n",
    "Somit ist dort (für $\\mu = \\mu_{0}$.) ein Minimum in der Gütefunktion (da Gütefunktion für eine wahre Nullhypothese möglichst klein ist)\n",
    "\\\n",
    "Für alle anderen Werte von $\\mu$, gilt die Alternativhypothese und die Nullhypothese wird abgelehnt.\n",
    "Dort ist dann die Gütefunktion größer (da eigentlich Nullhypothese richtig wäre), d.h. Gütefunktion wächst mit zunehmenden Abstand des Wertes $\\mu$ von $\\mu_{0}$.\n",
    "\\\n",
    "![alt text](gütefunktion.png \"Title\")\n",
    "\n",
    "Das bedeutet: \\\n",
    "Für die Fälle, dass Nullhypothese nicht abgelehnt wird, obwohl diese falsch ist. D.h. für einen wahren Parameter-Wert von $\\mu_{i} \\neq \\mu_{0}$.\\\n",
    "\\\n",
    "Bsp: Für einen wahren Parameter Wert von $\\mu_{1}$ mit einer großen Abweichung zu $\\mu_{0}$, ist der Fehler 2.Art ($\\beta$) kleiner als für einen Parameter $\\mu_{2}$ mit einer kleinen Abweichung zu $\\mu_{0}$. Für $\\mu_{2}$ ist der Fehler 2.Art groß.\n",
    "\n",
    "Quelle: https://wikis.hu-berlin.de/mmstat/Gütefunktion_des_Gauß-Tests\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Anwendung auf die Aufgabe:}$\n",
    "\n",
    "Das Signifikanzniveau $\\alpha$ gibt die Wahrscheinlichkeit an, dass Nullhypothese H0 fälschlicherweise abgelehnt wird, obwohl diese richtig ist. Dass heißt, $\\alpha$ ist Wahrscheinlichkeit $\\theta \\neq \\theta_{0}$, obwohl eigentlich $\\theta = \\theta_{0}$ richtig wäre. Hier sollte die Gütefunktion möglichst klein sein, da eigentlich H0 richtig ist.\n",
    "\\\n",
    "\\\n",
    "Gütefunktion (der Nullhypothese) ist stetig, sodass diese sich kontinuierlich für $\\theta$ verändert. Wenn $\\theta$ sich $\\theta_{0}$ nähert folgt, dass die Güte sich auch dem Wert der Güte von $\\theta_{0}$ nähert. \\\n",
    "Das Problem ist, dass die Alternative nur aus einem Punkt besteht, nämlich $\\theta = \\theta_{0}$, aber gleichzeitig die Gütefunktion stetig ist. Somit wird die Gütefunktion, um $\\theta_{0}$ nicht plötzlich auf null springen, sondern einen Wert größer als null haben. Das bedeutet, dass um den Punkt $\\theta_{0}$, es eine Wahrscheinlich gibt die Nullhypothese zu verwerfen, obwohl diese richtig wäre. Somit ist der Test nicht sinnvoll konzipiert. \n",
    "\n",
    "\\\n",
    "$\\textit{Alternative:}$\\\n",
    "Für den Fall, dass eine Nullhypothese H0, welche falsch ist, auch verworfen wird, ist dies ein korrektes Ergebnis. Somit gibt es keinen Fehler 1.Art (Signifikanzniveau $\\alpha$) und die Gütefunktion muss an dieser Stelle null sein (absolutes Minimum). \\\n",
    "D.h. Dieser Fall ist das bestmögliche Ergebnis, sodass jeder andere Test (wie beispielsweise der Test mit dem Hypothesenpaar $H0: \\Theta \\neq \\Theta_{0}$   $\\textbf{vs.}$ $H1: \\Theta = \\Theta_{0}$ ) eine schlechtere Güte ergibt.\\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textbf{Aufgabe 3.3}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Eine Person formuliert die Hypothese, die sie nachweisen m¨ochte, als H0. Ist dies ein sinnvolles\n",
    "Vorgehen? Begr¨unden Sie Ihre Antwort. \\\n",
    "(b) Es wird die Hypothese\n",
    "H0 : Stichprobe ist normalverteilt vs. H1 : Stichprobe ist nicht normalverteilt\n",
    "zum Niveau α = 0.05 getestet. Dabei ergibt sich ein p-Wert von 0.08. Die Nullhypothese kann\n",
    "also nicht abgelehnt werden. Die Person, die den Test durchgef¨uhrt hat, ist sich nun sicher, dass\n",
    "ihre Stichprobe normalverteilt ist. Ist dies sinnvoll? Wie f¨allt Ihre Antwort bei einem p-Wert von\n",
    "0.75 aus? Begr¨unden Sie Ihre Antworten. \\\n",
    "(c) Eine Person erh¨alt ein signifikantes Testergebnis. Kann sie sich sicher sein, dass sie damit etwas\n",
    "wissenschaftlich relevantes herausgefunden hat? Begr¨unden Sie Ihre Antwort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Antworten}:$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a): Nein, es wird die zu nachweisende Hypothese als Alternativhypothese H1 formuliert und die Nullhypothese H0 gibt die Gegenannahme. Dies liegt daran, da der Test darauf ausgelegt ist, die Nullhypothese zu widerlegen. Alle vorliegenden Test sind mit dieser Konvention erstellt, sodass es einen grundlegenden Unterschied gäbe und alle Test, um die Hypothese zu prüfen ebenfalls geändert werden müssten. Beispiele sind hierfür, unteranderm das Signifikanzniveau $\\alpha$, welches auf der Wahrscheinlichkeit der Nullhypothese abzulehnen basiert und damit ein Entscheidungskritierum ermöglicht. \\\n",
    "Es wäre somit unteranderem auch nicht wissenschaflich Vergleichbar und somit ein wenig sinnlos.\\\n",
    "\\\n",
    "(b): Nein, wenn die Nullhypothese nicht widerlegt wird, kann man nicht automatisch annehmen, dass diese richtig ist. Für einen p-Wert von 0.75 zeigt, dass wahrscheinlich die Nullhypothese annehmbar ist, jedoch könnte sie immernoch falsch sein (es gibt keinen 100% p-Wert ). Deswegen ist keine Aussage möglich, ob es sich um eine normalverteilte Stichprobe handelt.\\\n",
    "\\\n",
    "(c): Signifikantes Ergebnis zeigt, dass eine Abweichung von der Nullhypothese größer als eine zufällige ist. Somit kann die Nullhypothese abgelehnt werden, wodurch es sich um ein wissenschaftliches Ergebnis handelt, jedoch sollte aufjedenfall das entsprechnende Signifikanzniveau mit angegeben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
